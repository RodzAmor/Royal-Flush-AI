{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"9vJxHzAvJ3XV"}},{"cell_type":"code","source":["from collections import Counter\n","from dataclasses import dataclass\n","import numpy as np\n","import random"],"metadata":{"id":"SAXbGsrxJ7qR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Card and Deck Environment"],"metadata":{"id":"K_BO7V2DDJ5H"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXDTOnNtC6dV","executionInfo":{"status":"ok","timestamp":1714890331778,"user_tz":240,"elapsed":113,"user":{"displayName":"Vishnu Subramaniyan","userId":"09914821183781678501"}},"outputId":"073149b6-7953-49c2-afc9-d8f734cee800"},"outputs":[{"output_type":"stream","name":"stdout","text":["[2S, 7H, KD, JH, 4H]\n"]}],"source":["@dataclass\n","# Card class consists of rank and suit\n","class Card:\n","  rank: str\n","  suit: str\n","\n","  # Represent card as one char for rank and one char for suit\n","  def __repr__(self):\n","    return self.rank + self.suit\n","\n","  # Hash for each state representation\n","  def __hash__(self):\n","    return hash((self.rank, self.suit))\n","\n","# Deck class consists of cards and card functions\n","class Deck:\n","  def __init__(self):\n","    ranks = \"23456789TJQKA\" # Numbers, Ten, Jack, Queen, King, Ace\n","    suits = \"SHDC\" # Spades, Hearts, Diamonds, Clubs\n","\n","    # Generate one card of each rank/suit pair\n","    self.cards = [Card(rank, suit) for suit in suits for rank in ranks]\n","    self.shuffle()\n","\n","    # If number of cards isn't 52, something is wrong\n","    assert len(self.cards) == 52\n","\n","  # Shuffle deck of cards\n","  def shuffle(self):\n","    random.shuffle(self.cards)\n","\n","  # Draw random card without replacement\n","  def draw_card(self):\n","    if len(self.cards) == 0:\n","      raise ValueError(\"This shouldn't really happen. Maybe activate print_mode to figure out why.\")\n","\n","    return self.cards.pop()\n","\n","# Print out 5 cards\n","deck = Deck()\n","print(deck.cards[:5])"]},{"cell_type":"markdown","source":["# Agent (Player) State"],"metadata":{"id":"ltdAQj_UD4w6"}},{"cell_type":"code","source":["# Player class consists of several player properties\n","class Player:\n","  def __init__(self, player_name, bet = 20, starting_chips = 1000):\n","    self.player_name = player_name\n","    self.hand = []\n","    self.bet = bet  # Default bet amount is 20 chips\n","    self.chips = starting_chips # Default starting chips is 1000 chips\n","    self.active = True  # Player playing current game is True\n","\n","  # Draw starting hand (two cards)\n","  def draw_hand(self, deck):\n","    self.hand = [deck.draw_card() for i in range(2)]\n","\n","  # Show player hand\n","  def show_hand(self):\n","    return self.hand"],"metadata":{"id":"8XDR6pIOD7T7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Q-Learning Agent"],"metadata":{"id":"RGdjOX_XYa7O"}},{"cell_type":"code","source":["# QLearning class consists of similar setup/params as the RL HW\n","class QLearning:\n","  def __init__(self, alpha, gamma, n_actions, epsilon = 1.0, decay = 0.999, min_epsilon = 0.01):\n","    self.alpha = alpha\n","    self.gamma = gamma\n","    self.n_actions = n_actions\n","    self.epsilon = epsilon\n","    self.epsilon_decay = decay # Decay close to 1 becaure we're running thousands of simulations\n","    self.min_epsilon = min_epsilon # Want a small value for epsilon\n","    self.q_table = {}\n","\n","  def choose_action(self, state):\n","    if np.random.rand() < self.epsilon:\n","      return np.random.randint(self.n_actions) # Explores new action\n","    else:\n","      return np.argmax(self.q_table.get(state, np.zeros(self.n_actions))) # Exploits optimal action\n","\n","  def learn(self, state, action, reward, next_state):\n","    # Update q-table based on new info obtained\n","    current_q = self.q_table.get(state, np.zeros(self.n_actions))[action]\n","    highest_future_q = np.max(self.q_table.get(next_state, np.zeros(self.n_actions)))\n","    new_q = (1 - self.alpha) * current_q + self.alpha * (reward + self.gamma * highest_future_q)  # Bellman equation\n","\n","    self.q_table.setdefault(state, np.zeros(self.n_actions))[action] = new_q\n","    self.epsilon = max(self.min_epsilon, self.epsilon * self.epsilon_decay)"],"metadata":{"id":"ukBEs4l7YZDP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Poker Game Setup"],"metadata":{"id":"KUZiLf4jEdiY"}},{"cell_type":"code","source":["# PokerGame class consists of several game properties\n","class PokerGame:\n","  def __init__(self, players, print_mode=False):\n","    self.players = [Player(player_name) for player_name in players]\n","    self.deck = Deck()\n","    self.community_cards = [] # Face up cards\n","    self.pot = 0\n","    self.starting_chips = 1000\n","    self.current_bet = 20\n","\n","    # Default agent parameters\n","    self.agent = QLearning(alpha = 0.1, gamma = 0.9, n_actions = 4)\n","\n","    # Displaying output text mode (toggle)\n","    self.print_mode = print_mode\n","\n","  # Start new game (resets ALL deck and chip components)\n","  def start_new_game(self):\n","    self.deck = Deck()\n","    self.community_cards = []\n","    self.pot = 0\n","\n","    if self.print_mode:\n","      print(\"Starting new game\")\n","\n","    # All players are reinitialized and reset to default state\n","    for player in self.players:\n","      player.hand = []\n","      player.chips = self.starting_chips\n","      player.draw_hand(self.deck)\n","\n","      if self.print_mode:\n","        print(f\"{player.player_name}'s Hand: {player.show_hand()}\")\n","\n","  # Update chip amount in pot\n","  def update_pot(self, amount):\n","    self.pot += amount\n","\n","  # Update game/player properties based on player's move\n","  def player_action(self, player, action):\n","    if action == 0: # Player folds\n","      player.active = False\n","    elif action == 2: # Player checks\n","      self.update_pot(player.bet)\n","    elif action == 3: # Player raises\n","      raise_amount = self.current_bet\n","      self.current_bet = raise_amount\n","      self.update_pot(player.bet)\n","\n","  # Choose winner at end of game based on player's hand\n","  def determine_winner(self):\n","    active_players = [p for p in self.players if p.active]\n","    if not active_players:\n","      return None\n","\n","    best_hand = max(active_players, key = lambda p: self.evaluate_hand(p.hand + self.community_cards))\n","    best_hand.chips += self.pot\n","    return best_hand\n","\n","# Test player's starting hand\n","game = PokerGame([\"Andrie\", \"Dhruv\", \"Lawrence\", \"Vishnu\", \"Matthew\"], print_mode = True)\n","game.start_new_game()"],"metadata":{"id":"Xsp7VP0OEisk","executionInfo":{"status":"ok","timestamp":1714890336516,"user_tz":240,"elapsed":136,"user":{"displayName":"Vishnu Subramaniyan","userId":"09914821183781678501"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a03558b-ac45-4d90-bf2b-719f3009febc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting new game\n","Andrie's Hand: [KD, KS]\n","Dhruv's Hand: [AD, KC]\n","Lawrence's Hand: [AC, 7D]\n","Vishnu's Hand: [7C, QC]\n","Matthew's Hand: [4D, 3C]\n"]}]},{"cell_type":"markdown","source":["# Poker Game Setup (Deprecated Version)"],"metadata":{"id":"VTe9HTSQtD4X"}},{"cell_type":"code","source":["class PokerGame(PokerGame):\n","  # NOTE: This implementation is deprecated because there are too many states\n","  #       in poker that it would be impossible to map them all\n","\n","  '''def get_current_state(self):\n","    # Defaults to a single player vs AI\n","    # Different implementation necessary for several people\n","    player = self.players[0]\n","\n","    # Current state is tuple of values\n","    state = (tuple(player.show_hand()),\n","             tuple(self.community_cards),\n","             player.chips / self.starting_chips,\n","             self.pot / player.chips)\n","\n","    return state'''\n","\n","  # Initialize poker hand rankings\n","  def extract_features(self, player, stage):\n","    hand_cards = player.hand + self.community_cards\n","    hand_rank_tuple = self.evaluate_hand(hand_cards)\n","\n","    hand_strength = {\n","        \"High Card\": 1,\n","        \"One Pair\": 2,\n","        \"Two Pair\": 3,\n","        \"Three of a Kind\": 4,\n","        \"Straight\": 5,\n","        \"Flush\": 6,\n","        \"Full House\": 7,\n","        \"Four of a Kind\": 8,\n","        \"Straight Flush\": 9,\n","        \"Royal Flush\": 10\n","    }[hand_rank_tuple[0]]\n","\n","    '''pot_odds = None\n","\n","    # Prevents division by 0 errors\n","    if player.chips:\n","      pot_odds = self.pot / player.chips\n","    else:\n","      pot_odds = 1\n","\n","    relative_chips = player.chips / self.starting_chips\n","    return tuple([hand_strength, pot_odds, relative_chips])'''\n","\n","    active_players = len([player for player in self.players if player.active])\n","    return tuple([hand_strength, active_players, stage])\n","\n","  # New representation method abstracts some detail so RL agent can learn feasibly\n","  def get_current_state(self, player, stage):\n","    return self.extract_features(player, stage)\n","\n","  # Deal community cards\n","  def deal_community_cards(self, number):\n","    for i in range(number):\n","      self.community_cards.append(self.deck.draw_card())\n","\n","    # Debugging purposes\n","    if self.print_mode:\n","      print(f\"Comm Cards: {[str(card) for card in self.community_cards]}\")\n","\n","  # Simulate one full game of poker\n","  def simulate_game(self):\n","    self.start_new_game()\n","    stages = [(\"Pre flop\", 0), (\"Flop\", 3), (\"Turn\", 1), (\"River\", 1)]\n","\n","    # Loop through each stage in game\n","    for stage, num_cards in stages:\n","      if num_cards > 0:\n","        self.deal_community_cards(num_cards)\n","\n","      for player in self.players:\n","        # These commands don't matter much in this function since it only simulates one game\n","        state = self.get_current_state(player, stage)\n","        action = self.agent.choose_action(state)\n","        reward = self.evaluate_action(action, player)\n","\n","        next = self.get_current_state(player, stage)\n","        self.agent.learn(state, action, reward, next)\n","        self.player_action(player, action)\n","\n","        action_maps = [\"Fold\", \"Check\", \"Call\", \"Raise\"][action]\n","        if self.print_mode:\n","          print(f\"{player.name} decided to {action_maps}\")\n","          print(f\"Pot after betting: {self.pot}\")\n","          print(f\"Q values for current state: {self.agent.q_table.get(state, 'No actions')}\")\n","\n","        # Player folds\n","        if action == 0:\n","          break\n","\n","    winner = self.determine_winner()\n","    if winner and self.print_mode:\n","      print(f\"Winner is {winner.name} with {winner.chips} chips\")\n","\n","    self.pot = 0\n","\n","  # Compare strengths of a player's hand compared to another player's hand\n","  def compare_hands(self, hand_1, hand_2):\n","    eval_1 = self.evaluate_hand(hand_1)\n","    eval_2 = self.evaluate_hand(hand_2)\n","\n","    # Integer representation is fine for now\n","    hand_strength_mappings = {\n","        \"High Card\": 1,\n","        \"One Pair\": 2,\n","        \"Two Pair\": 3,\n","        \"Three of a Kind\": 4,\n","        \"Straight\": 5,\n","        \"Flush\": 6,\n","        \"Full House\": 7,\n","        \"Four of a Kind\": 8,\n","        \"Straight Flush\": 9,\n","        \"Royal Flush\": 10\n","    }\n","\n","    if hand_strength_mappings[eval_1[0]] > hand_strength_mappings[eval_2[0]]:\n","      return 1\n","    elif hand_strength_mappings[eval_1[0]] < hand_strength_mappings[eval_2[0]]:\n","      return -1\n","    else:\n","      if eval_1[1] > eval_2[1]:\n","        return 1\n","      elif eval_1[1] < eval_2[1]:\n","        return -1\n","      else:\n","        return 0 # Tie game"],"metadata":{"id":"DyZ78lS0s2Qd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Poker Class Evaluation Functions"],"metadata":{"id":"6lydd8pZaL1G"}},{"cell_type":"code","source":["class PokerGame(PokerGame):\n","  # Simulates many poker games and returns overall win rate\n","  def monte_carlo_eval(self, player, num_simulations = 1000):\n","    wins = 0\n","    original_deck = self.deck.cards.copy()\n","\n","    # Might need to lower this if you want to run extensive operations\n","    for i in range(num_simulations):  # Lower number of simulations if running extensive operations\n","      self.deck.cards = [card for card in original_deck if card not in player.hand and card not in self.community_cards]\n","      random.shuffle(self.deck.cards)\n","\n","      #  Opponent draws cards\n","      opponent_hand = [self.deck.draw_card() for i in range(2)]\n","      missing = 5 - len(self.community_cards)\n","\n","      simulated_comm_cards = self.community_cards + [self.deck.draw_card() for i in range(missing)]\n","\n","      if self.compare_hands(player.hand + simulated_comm_cards, opponent_hand + simulated_comm_cards) > 0:\n","        wins += 1\n","\n","    win_rate = wins / num_simulations\n","\n","    return win_rate\n","\n","  # Evaluate based on many different factors\n","  # Averages both the monte carlo win rate and the static hand strength\n","  def evaluate_action(self, action, player, base_reward = 10):\n","    # Probabilistic strength of the cards\n","    monte_carlo_strength = self.monte_carlo_eval(player, num_simulations=500)\n","\n","    # This part evaluates the static strength of the hand\n","    hand = player.hand + self.community_cards\n","    hand_rank = self.evaluate_hand(hand)[0]\n","\n","    hand_strength_mappings = {\n","        \"High Card\": 0.1,\n","        \"One Pair\": 0.2,\n","        \"Two Pair\": 0.3,\n","        \"Three of a Kind\": 0.4,\n","        \"Straight\": 0.5,\n","        \"Flush\": 0.6,\n","        \"Full House\": 0.7,\n","        \"Four of a Kind\": 0.8,\n","        \"Straight Flush\": 0.9,\n","        \"Royal Flush\": 1.0,\n","    }\n","    hand_strength = hand_strength_mappings[hand_rank]\n","\n","    # Add the mapping with the monte carlo strength\n","    # Monte carlo strength is just the win rate\n","    combined_strength = (monte_carlo_strength + hand_strength) / 2\n","\n","    pot_odds = self.pot / (self.pot + player.chips)\n","\n","    # Fold\n","    if action == 0:\n","      if combined_strength > 0.5 or pot_odds < combined_strength:\n","        return base_reward * -0.5 # Penalize for folding with strong hand\n","      else:\n","        return base_reward * 0.1 # Small Reward\n","\n","    # Call\n","    elif action == 1:\n","      if combined_strength > pot_odds:\n","        return base_reward * combined_strength # Reward based on strength\n","      else:\n","        return -base_reward * combined_strength # Penalize for calling with weak hand\n","\n","    # Raise\n","    elif action == 2:\n","      if combined_strength > 0.7:\n","        return base_reward * 2 * combined_strength # raise with strong hand\n","      else:\n","        return -base_reward * (1 - combined_strength) # penalty for bluffing with weak hand\n","\n","    else:\n","      return 0\n","\n","  def evaluate_hand(self, cards):\n","    ranks = \"23456789TJQKA\" # The number at the front of card\n","\n","    rank_counter = Counter(card.rank for card in cards)\n","    suit_counter = Counter(card.suit for card in cards)\n","\n","    rank_vals = {\n","        rank : index for index, rank in enumerate(ranks, start=2)\n","    }\n","\n","    sorted_ranks = sorted((rank_vals[rank], rank) for rank in rank_counter)\n","    sorted_ranks.reverse() # desc\n","\n","\n","    # Check for straight\n","    is_flush = max(suit_counter.values()) >= 5\n","    rank_seq = [rank_vals[rank] for rank in sorted(ranks, key=lambda rank: rank_vals[rank])]\n","    straight_high = None\n","\n","    for i in range(len(rank_seq) - 4):\n","      if rank_seq[i] - rank_seq[i + 4] == 4:\n","        straight_high = rank_seq[i] # Hand has a straight\n","        break\n","\n","    # I apologize for such inelegant code but hey, it works :D\n","    if 14 in rank_seq and 2 in rank_seq and 3 in rank_seq and 4 in rank_seq and 5 in rank_seq:\n","      straight_high = 5 # A2345\n","\n","\n","    counts = sorted(rank_counter.values(), reverse=True)\n","\n","    # hand_strength_mappings = {\n","    #     \"High Card\": 0.1,\n","    #     \"One Pair\": 0.2,\n","    #     \"Two Pair\": 0.3,\n","    #     \"Three of a Kind\": 0.4,\n","    #     \"Straight\": 0.5,\n","    #     \"Flush\": 0.6,\n","    #     \"Full House\": 0.7,\n","    #     \"Four of a Kind\": 0.8,\n","    #     \"Straight Flush\": 0.9,\n","    #     \"Royal Flush\": 1.0,\n","    # }\n","    # if straight_high and is is_flush:\n","\n","    if straight_high and is_flush:\n","      hand_type = \"Straight Flush\"\n","    elif counts[0] == 4:\n","      hand_type = \"Four of a Kind\"\n","    elif counts[0] == 3 and counts[1] == 2:\n","      hand_type = \"Full House\"\n","    elif is_flush:\n","      hand_type = \"Flush\"\n","    elif straight_high:\n","      hand_type = \"Straight\"\n","    elif counts[0] == 3:\n","      hand_type = \"Three of a Kind\"\n","    elif counts[0] == 2 and counts[1] == 2:\n","      hand_type = \"Two Pair\"\n","    elif counts[0] == 2:\n","      hand_type = \"One Pair\"\n","    elif counts[0] == 2:\n","      hand_type = \"Straight Flush\"\n","    else:\n","      hand_type = \"High Card\"\n","\n","    return (hand_type, straight_high if straight_high else sorted_ranks[0][0])"],"metadata":{"id":"IM_WaTCAaODv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Run Several Simulations and Run Reinforcement Learning over many Iterations"],"metadata":{"id":"ys2-J62_batP"}},{"cell_type":"code","source":["class PokerGame(PokerGame):\n","  def simulate_several_games(self, num_games):\n","    for game in range(num_games):\n","      self.start_new_game()\n","\n","      stages = [(\"Pre flop\", 0), (\"Flop\", 3), (\"Turn\", 1), (\"River\", 1)]\n","\n","      for stage, num_cards in stages:\n","        if num_cards > 0:\n","          # print(num_cards, len(self.community_cards))\n","          self.deal_community_cards(num_cards)\n","\n","        for player in self.players:\n","          state = self.get_current_state(player, stage)\n","          action = self.agent.choose_action(state)\n","\n","          reward = self.evaluate_action(action, player)\n","\n","          next = self.get_current_state(player, stage)\n","          self.agent.learn(state, action, reward, next)\n","\n","          # Uncomment this for the betting functionality\n","          # self.player_action(player, action)\n","\n","          # action_maps = [\"Fold\", \"Check\", \"Call\", \"Raise\"][action]\n","\n","      # Print game updates and q table every 100 games\n","      if game % 100 == 0:\n","        print(f\"Game {game}: Epsilon = {self.agent.epsilon}\")\n","        # print(f\"State: {state or 'No actions yet'}\")\n","        # print(f\"Q Values for State: {self.agent.q_table.get(state, 'No actions yet')}\")\n","\n","        # Print out the current Q Table\n","        for key, value in self.agent.q_table.items():\n","          print(f\"State: {key}, Q-values: {value}\")\n","\n","    # After running all he iterations, show the entire table\n","    print(\"Final Q Table\")\n","    for key, value in self.agent.q_table.items():\n","      print(f\"State: {key}, Q-values: {value}\")\n"],"metadata":{"id":"0h21kaqlbaXO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Simulate games"],"metadata":{"id":"JhV5TTgRZZoe"}},{"cell_type":"code","source":["# game = PokerGame([\"Andrie\", \"Dhruv\", \"Lawrence\", \"Vishnu\", \"Matthew\"], print_mode=False)\n","game = PokerGame([\"Andrie\", \"Dhruv\"], print_mode=False)\n","# game.start_new_game()\n","\n","num_games = 1000\n","game.simulate_several_games(num_games)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9HYrmd8pZZcq","executionInfo":{"status":"ok","timestamp":1714193474677,"user_tz":240,"elapsed":378386,"user":{"displayName":"Rodz Jumawid Amor","userId":"01190833105237107576"}},"outputId":"618331be-0bc5-4b56-ae35-9dad8a2d0dad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Game 0: Epsilon = 0.9920279440699441\n","State: (5, 2, 'Pre flop'), Q-values: [-0.5    0.    -0.732  0.   ]\n","State: (5, 2, 'Flop'), Q-values: [-0.5   0.   -0.75  0.  ]\n","State: (5, 2, 'Turn'), Q-values: [-0.4775  0.25    0.      0.    ]\n","State: (5, 2, 'River'), Q-values: [-0.5   0.   -0.75  0.  ]\n","Game 100: Epsilon = 0.4455685064764183\n","State: (5, 2, 'Pre flop'), Q-values: [ 4.65863967 16.97608564  2.16433055  9.6071688 ]\n","State: (5, 2, 'Flop'), Q-values: [ 3.09654555 15.76030294  1.67967788  8.93457475]\n","State: (5, 2, 'Turn'), Q-values: [ 6.70968315 16.77453877  2.98589728  8.73935167]\n","State: (5, 2, 'River'), Q-values: [ 3.84908347 14.03456245 -0.32653633  7.87479731]\n","State: (7, 2, 'Turn'), Q-values: [0.      0.596   0.      0.05364]\n","State: (7, 2, 'River'), Q-values: [0.       0.948935 1.2215   0.109935]\n","State: (9, 2, 'Turn'), Q-values: [0.    0.    1.828 0.   ]\n","State: (9, 2, 'River'), Q-values: [-0.19155826  0.944       3.4271304   0.        ]\n","State: (7, 2, 'Flop'), Q-values: [0. 0. 0. 0.]\n","Game 200: Epsilon = 0.20012671533134627\n","State: (5, 2, 'Pre flop'), Q-values: [14.62505559 25.03211514 11.316671   18.41085223]\n","State: (5, 2, 'Flop'), Q-values: [11.9894499  25.63592101  9.2936473  17.19149288]\n","State: (5, 2, 'Turn'), Q-values: [14.40214865 24.54971308  7.93960101 16.79952085]\n","State: (5, 2, 'River'), Q-values: [11.23754107 22.34179541  5.7409416  15.72483198]\n","State: (7, 2, 'Turn'), Q-values: [-0.23523601  3.50840388  0.          0.05364   ]\n","State: (7, 2, 'River'), Q-values: [ 0.          2.11355507 10.2101428   0.2088765 ]\n","State: (9, 2, 'Turn'), Q-values: [0.         0.         4.59625591 0.61692012]\n","State: (9, 2, 'River'), Q-values: [-0.19155826  0.944      13.23739225  1.05794475]\n","State: (7, 2, 'Flop'), Q-values: [-0.5  0.   0.   0. ]\n","Game 300: Epsilon = 0.08988674380520499\n","State: (5, 2, 'Pre flop'), Q-values: [16.21199828 27.11569193 14.38817751 20.86204773]\n","State: (5, 2, 'Flop'), Q-values: [14.82912848 26.88267901 12.6818714  19.96200532]\n","State: (5, 2, 'Turn'), Q-values: [15.62087742 26.00454715 12.11927586 19.64870737]\n","State: (5, 2, 'River'), Q-values: [13.63835902 24.5467032   9.81370028 16.70478643]\n","State: (7, 2, 'Turn'), Q-values: [-0.23523601  3.50840388  0.          0.05364   ]\n","State: (7, 2, 'River'), Q-values: [ 0.          2.11355507 10.76116645  0.2088765 ]\n","State: (9, 2, 'Turn'), Q-values: [0.0457864  0.         6.06429335 0.61692012]\n","State: (9, 2, 'River'), Q-values: [ 0.64654921  0.944      19.56925803  1.05794475]\n","State: (7, 2, 'Flop'), Q-values: [-0.5  0.   0.   0. ]\n","State: (9, 2, 'Flop'), Q-values: [-0.5  0.   0.   0. ]\n","State: (8, 2, 'River'), Q-values: [0.  0.9 0.  0. ]\n","Game 400: Epsilon = 0.04037255445143986\n","State: (5, 2, 'Pre flop'), Q-values: [17.31213465 27.14698674 15.30572081 21.81548826]\n","State: (5, 2, 'Flop'), Q-values: [14.82912848 26.86267982 13.0514209  19.96200532]\n","State: (5, 2, 'Turn'), Q-values: [16.54836719 26.45505179 13.42796299 21.14999736]\n","State: (5, 2, 'River'), Q-values: [14.32645623 24.92867226 11.169387   18.20988625]\n","State: (7, 2, 'Turn'), Q-values: [-0.23523601  4.28531984  0.          0.05364   ]\n","State: (7, 2, 'River'), Q-values: [ 0.          2.11355507 13.51189715  0.2088765 ]\n","State: (9, 2, 'Turn'), Q-values: [0.0457864  0.         9.22568397 0.61692012]\n","State: (9, 2, 'River'), Q-values: [ 0.64654921  0.944      26.68810346  1.05794475]\n","State: (7, 2, 'Flop'), Q-values: [-0.5  0.   0.   0. ]\n","State: (9, 2, 'Flop'), Q-values: [-0.5    0.876  0.     0.   ]\n","State: (8, 2, 'River'), Q-values: [0.  0.9 0.  0. ]\n","Game 500: Epsilon = 0.018133298459078098\n","State: (5, 2, 'Pre flop'), Q-values: [17.70887388 27.19137099 15.30572081 22.7139273 ]\n","State: (5, 2, 'Flop'), Q-values: [15.63506692 27.05905682 13.40827858 19.96200532]\n","State: (5, 2, 'Turn'), Q-values: [16.54836719 26.47836895 13.42796299 21.14999736]\n","State: (5, 2, 'River'), Q-values: [14.9232419  24.98831595 12.47520075 18.63746166]\n","State: (7, 2, 'Turn'), Q-values: [-0.23523601  4.28531984  0.          0.05364   ]\n","State: (7, 2, 'River'), Q-values: [ 0.          2.11355507 21.41307828  0.2088765 ]\n","State: (9, 2, 'Turn'), Q-values: [ 0.0457864   0.         16.08666231  0.61692012]\n","State: (9, 2, 'River'), Q-values: [ 0.64654921  0.944      34.98304765  1.05794475]\n","State: (7, 2, 'Flop'), Q-values: [-0.5  0.   0.   0. ]\n","State: (9, 2, 'Flop'), Q-values: [-0.5         3.54535192  0.          0.        ]\n","State: (8, 2, 'River'), Q-values: [0.  0.9 0.  0. ]\n","Game 600: Epsilon = 0.01\n","State: (5, 2, 'Pre flop'), Q-values: [17.70887388 27.36529813 15.70485859 22.7139273 ]\n","State: (5, 2, 'Flop'), Q-values: [15.63506692 27.11995432 13.40827858 20.40363492]\n","State: (5, 2, 'Turn'), Q-values: [16.99600276 26.55073262 14.07823235 21.14999736]\n","State: (5, 2, 'River'), Q-values: [14.9232419  24.99823392 12.72678531 19.02271547]\n","State: (7, 2, 'Turn'), Q-values: [-0.23523601  5.74479198  0.          0.05364   ]\n","State: (7, 2, 'River'), Q-values: [ 0.          2.11355507 25.53785744  0.2088765 ]\n","State: (9, 2, 'Turn'), Q-values: [ 0.0457864   0.         17.70979569  0.61692012]\n","State: (9, 2, 'River'), Q-values: [ 0.64654921  0.944      40.16160817  1.05794475]\n","State: (7, 2, 'Flop'), Q-values: [-0.5  0.   0.   0. ]\n","State: (9, 2, 'Flop'), Q-values: [-0.5         3.54535192  0.          0.        ]\n","State: (8, 2, 'River'), Q-values: [0.        2.5513591 0.        0.       ]\n","Game 700: Epsilon = 0.01\n","State: (5, 2, 'Pre flop'), Q-values: [17.70887388 27.28760037 15.70485859 22.7139273 ]\n","State: (5, 2, 'Flop'), Q-values: [16.00707758 26.95535932 13.40827858 20.40363492]\n","State: (5, 2, 'Turn'), Q-values: [16.99600276 26.31564958 14.07823235 21.85642671]\n","State: (5, 2, 'River'), Q-values: [14.9232419  24.99974098 12.72678531 19.02271547]\n","State: (7, 2, 'Turn'), Q-values: [-0.23523601  7.28608062  0.          0.05364   ]\n","State: (7, 2, 'River'), Q-values: [ 0.          2.11355507 31.59992457  0.2088765 ]\n","State: (9, 2, 'Turn'), Q-values: [ 0.0457864   0.         17.70979569  0.61692012]\n","State: (9, 2, 'River'), Q-values: [ 0.64654921  0.944      44.12600265  1.05794475]\n","State: (7, 2, 'Flop'), Q-values: [-0.5   0.84  0.    0.  ]\n","State: (9, 2, 'Flop'), Q-values: [-0.5         3.54535192  0.          0.        ]\n","State: (8, 2, 'River'), Q-values: [0.        2.5513591 0.        0.       ]\n","Game 800: Epsilon = 0.01\n","State: (5, 2, 'Pre flop'), Q-values: [17.70887388 27.30617567 15.83831835 22.88641961]\n","State: (5, 2, 'Flop'), Q-values: [16.00707758 26.76921332 13.40827858 20.77714867]\n","State: (5, 2, 'Turn'), Q-values: [16.99600276 26.37338973 14.07823235 22.04017964]\n","State: (5, 2, 'River'), Q-values: [15.18090533 24.99996201 12.72678531 19.37043349]\n","State: (7, 2, 'Turn'), Q-values: [-0.23523601  9.31157374  0.          0.05364   ]\n","State: (7, 2, 'River'), Q-values: [ 0.          2.11355507 35.17467721  0.2088765 ]\n","State: (9, 2, 'Turn'), Q-values: [ 0.0457864   0.         19.41869773  0.61692012]\n","State: (9, 2, 'River'), Q-values: [ 0.64654921  0.944      48.20126284  1.05794475]\n","State: (7, 2, 'Flop'), Q-values: [-0.5   0.84  0.    0.  ]\n","State: (9, 2, 'Flop'), Q-values: [-0.5        4.4308984  0.         0.       ]\n","State: (8, 2, 'River'), Q-values: [0.         3.39884551 0.         0.        ]\n","State: (8, 2, 'Turn'), Q-values: [-0.5  0.   0.   0. ]\n","Game 900: Epsilon = 0.01\n","State: (5, 2, 'Pre flop'), Q-values: [17.89123207 27.20225946 15.83831835 22.88641961]\n","State: (5, 2, 'Flop'), Q-values: [16.00707758 26.75616583 13.81052989 21.12699891]\n","State: (5, 2, 'Turn'), Q-values: [17.19186529 26.25729524 14.07823235 22.24722475]\n","State: (5, 2, 'River'), Q-values: [15.41281267 24.99999396 12.95410622 19.37043349]\n","State: (7, 2, 'Turn'), Q-values: [-0.23523601 10.69140342  0.          0.05364   ]\n","State: (7, 2, 'River'), Q-values: [ 0.          2.11355507 37.64790569  0.2088765 ]\n","State: (9, 2, 'Turn'), Q-values: [ 0.0457864   0.         24.36826819  0.61692012]\n","State: (9, 2, 'River'), Q-values: [ 0.64654921  0.944      58.21746175  1.05794475]\n","State: (7, 2, 'Flop'), Q-values: [-0.5   0.84  0.    0.  ]\n","State: (9, 2, 'Flop'), Q-values: [-0.5         6.07573353  0.          0.        ]\n","State: (8, 2, 'River'), Q-values: [-0.1941039   4.13685705  0.          0.        ]\n","State: (8, 2, 'Turn'), Q-values: [-0.5      1.73201  0.       0.     ]\n","State: (8, 2, 'Flop'), Q-values: [-0.5    0.882  0.     0.   ]\n","Final Q Table\n","State: (5, 2, 'Pre flop'), Q-values: [17.89123207 27.27866247 15.83831835 22.88641961]\n","State: (5, 2, 'Flop'), Q-values: [16.61375948 27.569794   13.81052989 21.12699891]\n","State: (5, 2, 'Turn'), Q-values: [17.19186529 26.84763839 14.28020482 22.53892025]\n","State: (5, 2, 'River'), Q-values: [15.62153128 24.99999902 12.95410622 19.37043349]\n","State: (7, 2, 'Turn'), Q-values: [-0.23523601 11.33148939  0.          0.05364   ]\n","State: (7, 2, 'River'), Q-values: [ 0.          2.11355507 40.11813237  0.2088765 ]\n","State: (9, 2, 'Turn'), Q-values: [ 0.0457864   0.         27.19437966  0.61692012]\n","State: (9, 2, 'River'), Q-values: [ 0.64654921  0.944      67.17552443  6.91156159]\n","State: (7, 2, 'Flop'), Q-values: [-0.5   0.84  0.    0.  ]\n","State: (9, 2, 'Flop'), Q-values: [-0.5         6.07573353  0.          0.        ]\n","State: (8, 2, 'River'), Q-values: [-0.1941039   5.69207826  0.          0.        ]\n","State: (8, 2, 'Turn'), Q-values: [-0.5        2.6076899  0.         0.       ]\n","State: (8, 2, 'Flop'), Q-values: [-0.5    0.882  0.     0.   ]\n"]}]}]}